{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practical_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2_n7onVSeng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2bafaf0-7373-49c3-fb18-51c6c14b99e5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14x8dXhYozVR"
      },
      "source": [
        "import torch\n",
        "import dlc_practical_prologue as prologue"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVvbmF3Im_TX"
      },
      "source": [
        "# Question 1.1\n",
        "\n",
        "# https://dustinstansbury.github.io/theclevermachine/derivation-common-neural-network-activation-functions\n",
        "\n",
        "\"\"\"\n",
        "tanh --> gtanh(x) = (2 / (1 + e**(-2*x)) ) - 1 \n",
        "\"\"\"\n",
        "# param: float tensor\n",
        "# return: float tensor\n",
        "def sigma(x):\n",
        "  f = (2 / (1 + torch.exp(x.mul(-2))) ) - 1\n",
        "  # f = x.tanh()\n",
        "  return f"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsarvre4oy1k"
      },
      "source": [
        "# Question 1.2\n",
        "\n",
        "\"\"\"\n",
        "tanh der --> gtanh'(x) = 1 - tanh**2(x)\n",
        "\"\"\"\n",
        "# param: float tensor\n",
        "# return: float tensor\n",
        "def dsigma(x):\n",
        "  df = 1 - sigma(x).pow(2)\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QtFgwt2qtkO",
        "outputId": "7c07509f-6655-4b8d-b412-710a9d865370"
      },
      "source": [
        "x_test = torch.zeros(1,10) + 1 # torch.ones(10)\n",
        "df = dsigma(x_test)\n",
        "print(df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4200, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200,\n",
            "         0.4200]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcJl1b8pq_Dg"
      },
      "source": [
        "# Question 2.1\n",
        "\n",
        "# p-norms: https://towardsdatascience.com/calculating-vector-p-norms-linear-algebra-for-data-science-iv-400511cffcf0\n",
        "# Euclidean distance: https://www.dabblingbadger.com/blog/2020/2/27/implementing-euclidean-distance-matrix-calculations-from-scratch-in-python\n",
        "def loss(v,t):\n",
        "  return (v - t).pow(2).sum().mean() # https://hackernoon.com/photos/0s78blBiawOe4UYlnA9SeCIgjbA3-uy1263zz5\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqR8ZhX50C4J"
      },
      "source": [
        "# Question 2.2\n",
        "\n",
        "# https://towardsdatascience.com/step-by-step-the-math-behind-neural-networks-d002440227fb\n",
        "def dloss(v,t):\n",
        "  return (v - t).mul(2) # torch.div(((v - t).mul(2)),v.shape[0]) # 2 * (v-t) # https://hackernoon.com/photos/0s78blBiawOe4UYlnA9SeCIgjbA3-wp15t3za8"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWBK7PlX2fXb",
        "outputId": "7564f90f-b0f7-4881-c45b-1195bd2c13f2"
      },
      "source": [
        "v_test = torch.zeros(1,10).fill_(6) #\n",
        "t_test = torch.zeros(1,10).fill_(2)\n",
        "l = loss(v_test, t_test)\n",
        "print(l)\n",
        "\n",
        "dl = dloss(v_test, t_test)\n",
        "print(dl)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(160.)\n",
            "tensor([[8., 8., 8., 8., 8., 8., 8., 8., 8., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmf5q8T6z-jj"
      },
      "source": [
        "# Question 3.1\n",
        "\n",
        "# https://miro.medium.com/max/700/1*_PhOCrD3sPgPKRIaTv4-Gg.png\n",
        "# https://youtu.be/bH6VnezBZfI?t=629\n",
        "\n",
        "def forward_pass(w1, b1, w2, b2, x):\n",
        "\n",
        "  s_1 = (w1 @ x) + b1 # dot product # L1\n",
        "  x_1 = sigma(s_1)\n",
        "\n",
        "  s_2 = (w2 @ x_1) + b2 # dot product # L2\n",
        "  x_2 = sigma(s_2)\n",
        "\n",
        "  return x, s_1, x_1 , s_2, x_2\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCHh0ppmR8w3"
      },
      "source": [
        "\"\"\"\n",
        "def backward_pass(w1, b1, w2, b2, \n",
        "                  t, \n",
        "                  x, s1, x1, s2, x2, \n",
        "                  dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
        "    x0 = x\n",
        "    dl_dx2 = dloss(x2, t)\n",
        "    dl_ds2 = dsigma(s2) * dl_dx2\n",
        "\n",
        "    dl_dx1 = w2.t().mv(dl_ds2) \n",
        "    dl_ds1 = dsigma(s1) * dl_dx1\n",
        "    \n",
        "    dl_dw2.add_(dl_ds2.view(-1, 1).mm(x1.view(1, -1)))\n",
        "    dl_db2.add_(dl_ds2)\n",
        "\n",
        "    dl_dw1.add_(dl_ds1.view(-1, 1).mm(x0.view(1, -1)))\n",
        "    dl_db1.add_(dl_ds1)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5XY8Vn_tQzR"
      },
      "source": [
        "# Question 3.2\n",
        "\n",
        "# https://youtu.be/6RUwfKNdaV0?list=PLaXDtXvwY-oDvedS3f4HW0b4KxqpJ_imw&t=171\n",
        "\n",
        "# 1 hidden layer\n",
        "# 1 output layer\n",
        "# wi.t() ---> https://www.kaggle.com/soham1024/basic-neural-network-from-scratch-in-python?scriptVersionId=33631402&cellId=14\n",
        "\"\"\"\n",
        "z = w * a + b \n",
        "Chain rule:\n",
        "\n",
        "∂C/∂wi = ∂z/∂w * ∂a/∂z * ∂C/∂a\n",
        "\n",
        "where \n",
        "\n",
        "∂z/∂w = z'(w) = a\n",
        "∂a/∂z = a'(z) = activation'(z) = sigma'(z)\n",
        "∂C/∂a = cost'(a) = 1/n sum(y - a)\n",
        "\n",
        "∂C/∂w = a * activation'(z) * cost'(a)\n",
        "\"\"\"\n",
        "\n",
        "def backward_pass(  w1, b1, w2, b2,\n",
        "                  t,\n",
        "                  x, s1, x1, s2, x2,\n",
        "                  dl_dw1, dl_db1, dl_dw2, dl_db2):\n",
        "\n",
        "    delta3 = dloss(x2, t)  # x2 - t # [10]\n",
        "    term2 = (delta3 * dsigma(s2))  # [10]\n",
        "    delta2 = w2.t().mm(term2.view(-1, 1))  # [300,1] = [300,10] . [10,1]\n",
        "\n",
        "    dl_dw2.add_(term2.view(-1, 1).mm(x1.view(-1, 1).t().view(1, -1)))  # [10,300] = [10, 1] . [1,300]\n",
        "    dl_db2.add_(term2)  # [10] = [10] .* [10]\n",
        "\n",
        "    term1 = (delta2.squeeze() * dsigma(s1)).view(-1,1)  # [300,1] = [300,1] .* [300] -> [300] .* [300]\n",
        "    dl_dw1.add_((term1).view(-1, 1).mm(x.view(-1, 1).t().view(1, -1)))  # [300,784] = [300,1] . [1,784]\n",
        "    dl_db1.add_(term1.squeeze())  # [300] = [300,1] --> [300]\n",
        "\n",
        "    return dl_dw1, dl_db1, dl_dw2, dl_db2  # [300,784], [300], [10,300], [10]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG16jk0FTgho",
        "outputId": "a0b78715-ff1b-4822-fd8e-9a4575903c23"
      },
      "source": [
        "#TRAIN\n",
        "#####################################################################\n",
        "\n",
        "train_input, train_target, test_input, test_target = prologue.load_data(one_hot_labels = True,\n",
        "                                                                        normalize = True)\n",
        "\n",
        "nb_classes = train_target.size(1)\n",
        "nb_train_samples = train_input.size(0)\n",
        "\n",
        "zeta = 0.90\n",
        "\n",
        "train_input = train_input * zeta\n",
        "test_input = test_input * zeta\n",
        "\n",
        "nb_hidden = 50\n",
        "eta = 1e-1 / nb_train_samples\n",
        "epsilon = 1e-6\n",
        "\n",
        "w1 = torch.empty(nb_hidden, train_input.size(1)).normal_(0, epsilon)\n",
        "b1 = torch.empty(nb_hidden).normal_(0, epsilon)\n",
        "w2 = torch.empty(nb_classes, nb_hidden).normal_(0, epsilon)\n",
        "b2 = torch.empty(nb_classes).normal_(0, epsilon)\n",
        "\n",
        "dl_dw1 = torch.empty(w1.size())\n",
        "dl_db1 = torch.empty(b1.size())\n",
        "dl_dw2 = torch.empty(w2.size())\n",
        "dl_db2 = torch.empty(b2.size())\n",
        "\n",
        "for k in range(200):\n",
        "\n",
        "    # Back-prop\n",
        "\n",
        "    acc_loss = 0\n",
        "    nb_train_errors = 0\n",
        "\n",
        "    dl_dw1.zero_()\n",
        "    dl_db1.zero_()\n",
        "    dl_dw2.zero_()\n",
        "    dl_db2.zero_()\n",
        "\n",
        "    for n in range(nb_train_samples):\n",
        "        x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, train_input[n])\n",
        "\n",
        "        pred = x2.max(0)[1].item()\n",
        "        if train_target[n, pred] < 0.5: nb_train_errors = nb_train_errors + 1\n",
        "        acc_loss = acc_loss + loss(x2, train_target[n])\n",
        "\n",
        "        backward_pass(w1, b1, w2, b2,\n",
        "                      train_target[n],\n",
        "                      x0, s1, x1, s2, x2,\n",
        "                      dl_dw1, dl_db1, dl_dw2, dl_db2)\n",
        "\n",
        "    # Gradient step\n",
        "\n",
        "    w1 = w1 - eta * dl_dw1\n",
        "    b1 = b1 - eta * dl_db1\n",
        "    w2 = w2 - eta * dl_dw2\n",
        "    b2 = b2 - eta * dl_db2\n",
        "\n",
        "    # Test error\n",
        "\n",
        "    nb_test_errors = 0\n",
        "\n",
        "    for n in range(test_input.size(0)):\n",
        "        _, _, _, _, x2 = forward_pass(w1, b1, w2, b2, test_input[n])\n",
        "\n",
        "        pred = x2.max(0)[1].item()\n",
        "        if test_target[n, pred] < 0.5: nb_test_errors = nb_test_errors + 1\n",
        "\n",
        "    print('{:d} acc_train_loss {:.02f} acc_train_error {:.02f}% test_error {:.02f}%'\n",
        "          .format(k,\n",
        "                  acc_loss,\n",
        "                  (100 * nb_train_errors) / train_input.size(0),\n",
        "                  (100 * nb_test_errors) / test_input.size(0)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Using MNIST\n",
            "** Reduce the data-set (use --full for the full thing)\n",
            "** Use 1000 train and 1000 test samples\n",
            "0 acc_train_loss 1000.00 acc_train_error 88.30% test_error 90.10%\n",
            "1 acc_train_loss 963.68 acc_train_error 88.30% test_error 90.10%\n",
            "2 acc_train_loss 940.46 acc_train_error 88.30% test_error 90.10%\n",
            "3 acc_train_loss 925.61 acc_train_error 88.30% test_error 90.10%\n",
            "4 acc_train_loss 916.12 acc_train_error 88.30% test_error 90.10%\n",
            "5 acc_train_loss 910.03 acc_train_error 88.30% test_error 90.10%\n",
            "6 acc_train_loss 906.13 acc_train_error 88.30% test_error 90.10%\n",
            "7 acc_train_loss 903.63 acc_train_error 88.30% test_error 90.10%\n",
            "8 acc_train_loss 902.02 acc_train_error 88.30% test_error 90.10%\n",
            "9 acc_train_loss 900.98 acc_train_error 88.30% test_error 90.10%\n",
            "10 acc_train_loss 900.32 acc_train_error 88.30% test_error 90.10%\n",
            "11 acc_train_loss 899.88 acc_train_error 88.30% test_error 90.10%\n",
            "12 acc_train_loss 899.61 acc_train_error 88.30% test_error 90.10%\n",
            "13 acc_train_loss 899.43 acc_train_error 88.30% test_error 90.10%\n",
            "14 acc_train_loss 899.31 acc_train_error 88.30% test_error 90.10%\n",
            "15 acc_train_loss 899.24 acc_train_error 88.30% test_error 90.10%\n",
            "16 acc_train_loss 899.19 acc_train_error 88.30% test_error 90.10%\n",
            "17 acc_train_loss 899.16 acc_train_error 88.30% test_error 90.10%\n",
            "18 acc_train_loss 899.13 acc_train_error 88.30% test_error 90.10%\n",
            "19 acc_train_loss 899.12 acc_train_error 88.30% test_error 90.10%\n",
            "20 acc_train_loss 899.10 acc_train_error 88.30% test_error 90.10%\n",
            "21 acc_train_loss 899.07 acc_train_error 88.30% test_error 90.10%\n",
            "22 acc_train_loss 899.05 acc_train_error 88.30% test_error 90.10%\n",
            "23 acc_train_loss 899.00 acc_train_error 88.30% test_error 90.10%\n",
            "24 acc_train_loss 898.91 acc_train_error 88.30% test_error 90.10%\n",
            "25 acc_train_loss 898.75 acc_train_error 88.30% test_error 90.10%\n",
            "26 acc_train_loss 898.48 acc_train_error 88.30% test_error 83.00%\n",
            "27 acc_train_loss 898.00 acc_train_error 80.00% test_error 79.40%\n",
            "28 acc_train_loss 897.16 acc_train_error 78.30% test_error 79.30%\n",
            "29 acc_train_loss 895.69 acc_train_error 78.90% test_error 78.60%\n",
            "30 acc_train_loss 893.16 acc_train_error 75.40% test_error 74.70%\n",
            "31 acc_train_loss 888.92 acc_train_error 70.90% test_error 73.70%\n",
            "32 acc_train_loss 882.12 acc_train_error 70.80% test_error 73.80%\n",
            "33 acc_train_loss 871.87 acc_train_error 71.30% test_error 74.10%\n",
            "34 acc_train_loss 857.79 acc_train_error 71.40% test_error 74.20%\n",
            "35 acc_train_loss 840.53 acc_train_error 71.30% test_error 73.30%\n",
            "36 acc_train_loss 821.84 acc_train_error 70.60% test_error 72.30%\n",
            "37 acc_train_loss 803.52 acc_train_error 69.50% test_error 71.70%\n",
            "38 acc_train_loss 786.63 acc_train_error 68.60% test_error 70.50%\n",
            "39 acc_train_loss 772.14 acc_train_error 67.60% test_error 69.90%\n",
            "40 acc_train_loss 761.06 acc_train_error 66.70% test_error 69.30%\n",
            "41 acc_train_loss 753.24 acc_train_error 66.40% test_error 68.70%\n",
            "42 acc_train_loss 747.26 acc_train_error 65.60% test_error 67.70%\n",
            "43 acc_train_loss 741.54 acc_train_error 64.60% test_error 66.30%\n",
            "44 acc_train_loss 735.02 acc_train_error 62.30% test_error 63.60%\n",
            "45 acc_train_loss 727.24 acc_train_error 58.70% test_error 60.70%\n",
            "46 acc_train_loss 718.19 acc_train_error 56.10% test_error 58.40%\n",
            "47 acc_train_loss 708.38 acc_train_error 52.70% test_error 55.70%\n",
            "48 acc_train_loss 698.71 acc_train_error 50.10% test_error 54.40%\n",
            "49 acc_train_loss 690.15 acc_train_error 48.20% test_error 53.20%\n",
            "50 acc_train_loss 683.18 acc_train_error 47.10% test_error 51.70%\n",
            "51 acc_train_loss 677.66 acc_train_error 46.40% test_error 50.70%\n",
            "52 acc_train_loss 673.03 acc_train_error 45.80% test_error 50.10%\n",
            "53 acc_train_loss 668.69 acc_train_error 45.30% test_error 49.20%\n",
            "54 acc_train_loss 664.18 acc_train_error 43.90% test_error 48.10%\n",
            "55 acc_train_loss 659.24 acc_train_error 43.50% test_error 47.10%\n",
            "56 acc_train_loss 653.73 acc_train_error 42.80% test_error 46.20%\n",
            "57 acc_train_loss 647.61 acc_train_error 42.80% test_error 45.80%\n",
            "58 acc_train_loss 640.91 acc_train_error 42.30% test_error 44.40%\n",
            "59 acc_train_loss 633.77 acc_train_error 41.60% test_error 43.80%\n",
            "60 acc_train_loss 626.35 acc_train_error 40.30% test_error 43.00%\n",
            "61 acc_train_loss 618.79 acc_train_error 39.50% test_error 42.10%\n",
            "62 acc_train_loss 611.23 acc_train_error 38.30% test_error 40.80%\n",
            "63 acc_train_loss 603.68 acc_train_error 36.10% test_error 39.70%\n",
            "64 acc_train_loss 596.10 acc_train_error 34.60% test_error 38.40%\n",
            "65 acc_train_loss 588.40 acc_train_error 32.50% test_error 37.40%\n",
            "66 acc_train_loss 580.51 acc_train_error 31.60% test_error 36.40%\n",
            "67 acc_train_loss 572.39 acc_train_error 30.40% test_error 35.20%\n",
            "68 acc_train_loss 564.09 acc_train_error 29.80% test_error 33.90%\n",
            "69 acc_train_loss 555.68 acc_train_error 29.30% test_error 32.90%\n",
            "70 acc_train_loss 547.28 acc_train_error 28.10% test_error 31.90%\n",
            "71 acc_train_loss 539.02 acc_train_error 27.10% test_error 31.80%\n",
            "72 acc_train_loss 530.99 acc_train_error 25.50% test_error 30.50%\n",
            "73 acc_train_loss 523.27 acc_train_error 24.60% test_error 30.60%\n",
            "74 acc_train_loss 515.91 acc_train_error 23.60% test_error 30.00%\n",
            "75 acc_train_loss 508.97 acc_train_error 22.70% test_error 29.90%\n",
            "76 acc_train_loss 502.46 acc_train_error 22.10% test_error 29.20%\n",
            "77 acc_train_loss 496.42 acc_train_error 21.60% test_error 28.50%\n",
            "78 acc_train_loss 490.84 acc_train_error 21.00% test_error 28.00%\n",
            "79 acc_train_loss 485.70 acc_train_error 21.10% test_error 27.90%\n",
            "80 acc_train_loss 480.98 acc_train_error 20.90% test_error 27.70%\n",
            "81 acc_train_loss 476.63 acc_train_error 20.90% test_error 27.30%\n",
            "82 acc_train_loss 472.59 acc_train_error 20.80% test_error 27.00%\n",
            "83 acc_train_loss 468.81 acc_train_error 20.90% test_error 27.00%\n",
            "84 acc_train_loss 465.25 acc_train_error 20.60% test_error 26.70%\n",
            "85 acc_train_loss 461.90 acc_train_error 20.60% test_error 26.90%\n",
            "86 acc_train_loss 458.82 acc_train_error 19.80% test_error 26.50%\n",
            "87 acc_train_loss 456.28 acc_train_error 20.40% test_error 27.20%\n",
            "88 acc_train_loss 455.23 acc_train_error 18.80% test_error 26.90%\n",
            "89 acc_train_loss 458.62 acc_train_error 21.20% test_error 25.80%\n",
            "90 acc_train_loss 473.59 acc_train_error 18.20% test_error 31.70%\n",
            "91 acc_train_loss 510.96 acc_train_error 25.50% test_error 27.30%\n",
            "92 acc_train_loss 535.23 acc_train_error 18.50% test_error 31.30%\n",
            "93 acc_train_loss 514.14 acc_train_error 22.80% test_error 27.90%\n",
            "94 acc_train_loss 473.58 acc_train_error 19.50% test_error 31.10%\n",
            "95 acc_train_loss 501.27 acc_train_error 19.50% test_error 32.20%\n",
            "96 acc_train_loss 550.47 acc_train_error 25.10% test_error 34.20%\n",
            "97 acc_train_loss 513.57 acc_train_error 21.10% test_error 28.20%\n",
            "98 acc_train_loss 448.34 acc_train_error 18.70% test_error 25.50%\n",
            "99 acc_train_loss 435.34 acc_train_error 15.80% test_error 26.70%\n",
            "100 acc_train_loss 434.38 acc_train_error 17.00% test_error 24.70%\n",
            "101 acc_train_loss 440.39 acc_train_error 15.80% test_error 29.30%\n",
            "102 acc_train_loss 454.17 acc_train_error 18.90% test_error 26.90%\n",
            "103 acc_train_loss 467.76 acc_train_error 17.70% test_error 29.00%\n",
            "104 acc_train_loss 464.77 acc_train_error 19.30% test_error 26.20%\n",
            "105 acc_train_loss 445.89 acc_train_error 16.20% test_error 25.10%\n",
            "106 acc_train_loss 456.08 acc_train_error 14.60% test_error 30.30%\n",
            "107 acc_train_loss 486.75 acc_train_error 20.50% test_error 25.40%\n",
            "108 acc_train_loss 492.25 acc_train_error 14.30% test_error 29.70%\n",
            "109 acc_train_loss 448.74 acc_train_error 20.20% test_error 21.70%\n",
            "110 acc_train_loss 422.54 acc_train_error 11.80% test_error 28.30%\n",
            "111 acc_train_loss 428.62 acc_train_error 17.50% test_error 23.30%\n",
            "112 acc_train_loss 440.31 acc_train_error 12.80% test_error 28.50%\n",
            "113 acc_train_loss 439.42 acc_train_error 18.10% test_error 22.50%\n",
            "114 acc_train_loss 414.01 acc_train_error 13.00% test_error 24.20%\n",
            "115 acc_train_loss 391.69 acc_train_error 13.30% test_error 22.00%\n",
            "116 acc_train_loss 380.56 acc_train_error 12.40% test_error 22.00%\n",
            "117 acc_train_loss 374.66 acc_train_error 11.60% test_error 22.00%\n",
            "118 acc_train_loss 371.20 acc_train_error 12.60% test_error 20.80%\n",
            "119 acc_train_loss 368.79 acc_train_error 10.40% test_error 22.10%\n",
            "120 acc_train_loss 368.15 acc_train_error 13.10% test_error 19.90%\n",
            "121 acc_train_loss 369.83 acc_train_error 9.90% test_error 23.30%\n",
            "122 acc_train_loss 376.24 acc_train_error 13.40% test_error 20.90%\n",
            "123 acc_train_loss 389.80 acc_train_error 10.70% test_error 24.70%\n",
            "124 acc_train_loss 406.85 acc_train_error 14.00% test_error 23.00%\n",
            "125 acc_train_loss 415.57 acc_train_error 12.40% test_error 23.00%\n",
            "126 acc_train_loss 400.57 acc_train_error 13.20% test_error 23.80%\n",
            "127 acc_train_loss 385.25 acc_train_error 12.70% test_error 22.20%\n",
            "128 acc_train_loss 387.15 acc_train_error 11.30% test_error 26.40%\n",
            "129 acc_train_loss 397.70 acc_train_error 14.30% test_error 23.70%\n",
            "130 acc_train_loss 410.12 acc_train_error 12.00% test_error 26.30%\n",
            "131 acc_train_loss 403.54 acc_train_error 15.00% test_error 22.40%\n",
            "132 acc_train_loss 388.25 acc_train_error 10.60% test_error 22.70%\n",
            "133 acc_train_loss 378.53 acc_train_error 12.10% test_error 21.10%\n",
            "134 acc_train_loss 374.51 acc_train_error 11.10% test_error 22.10%\n",
            "135 acc_train_loss 372.12 acc_train_error 10.50% test_error 21.90%\n",
            "136 acc_train_loss 367.83 acc_train_error 11.90% test_error 20.60%\n",
            "137 acc_train_loss 360.90 acc_train_error 9.40% test_error 21.50%\n",
            "138 acc_train_loss 355.49 acc_train_error 11.30% test_error 20.60%\n",
            "139 acc_train_loss 352.38 acc_train_error 9.20% test_error 21.30%\n",
            "140 acc_train_loss 351.93 acc_train_error 10.80% test_error 19.80%\n",
            "141 acc_train_loss 354.96 acc_train_error 9.40% test_error 21.40%\n",
            "142 acc_train_loss 355.91 acc_train_error 10.50% test_error 20.90%\n",
            "143 acc_train_loss 358.34 acc_train_error 9.80% test_error 20.70%\n",
            "144 acc_train_loss 352.10 acc_train_error 10.10% test_error 20.80%\n",
            "145 acc_train_loss 348.35 acc_train_error 9.20% test_error 20.00%\n",
            "146 acc_train_loss 339.83 acc_train_error 10.00% test_error 20.40%\n",
            "147 acc_train_loss 337.02 acc_train_error 8.80% test_error 18.90%\n",
            "148 acc_train_loss 335.59 acc_train_error 10.20% test_error 21.30%\n",
            "149 acc_train_loss 340.45 acc_train_error 9.00% test_error 21.30%\n",
            "150 acc_train_loss 350.46 acc_train_error 11.00% test_error 23.00%\n",
            "151 acc_train_loss 362.67 acc_train_error 10.50% test_error 22.70%\n",
            "152 acc_train_loss 367.68 acc_train_error 12.30% test_error 22.10%\n",
            "153 acc_train_loss 356.05 acc_train_error 10.10% test_error 21.10%\n",
            "154 acc_train_loss 339.29 acc_train_error 11.60% test_error 19.10%\n",
            "155 acc_train_loss 328.98 acc_train_error 7.80% test_error 21.40%\n",
            "156 acc_train_loss 328.50 acc_train_error 11.00% test_error 19.20%\n",
            "157 acc_train_loss 340.41 acc_train_error 8.50% test_error 23.90%\n",
            "158 acc_train_loss 371.38 acc_train_error 12.40% test_error 22.40%\n",
            "159 acc_train_loss 411.07 acc_train_error 11.10% test_error 27.70%\n",
            "160 acc_train_loss 426.58 acc_train_error 15.00% test_error 22.00%\n",
            "161 acc_train_loss 363.38 acc_train_error 10.10% test_error 19.20%\n",
            "162 acc_train_loss 337.25 acc_train_error 8.80% test_error 21.50%\n",
            "163 acc_train_loss 326.34 acc_train_error 9.30% test_error 18.40%\n",
            "164 acc_train_loss 320.33 acc_train_error 7.50% test_error 20.50%\n",
            "165 acc_train_loss 314.83 acc_train_error 9.20% test_error 18.80%\n",
            "166 acc_train_loss 311.39 acc_train_error 7.70% test_error 19.80%\n",
            "167 acc_train_loss 309.91 acc_train_error 8.90% test_error 18.90%\n",
            "168 acc_train_loss 312.04 acc_train_error 7.40% test_error 19.90%\n",
            "169 acc_train_loss 317.24 acc_train_error 8.80% test_error 18.80%\n",
            "170 acc_train_loss 325.87 acc_train_error 7.20% test_error 20.70%\n",
            "171 acc_train_loss 332.85 acc_train_error 9.00% test_error 19.80%\n",
            "172 acc_train_loss 334.70 acc_train_error 7.70% test_error 19.60%\n",
            "173 acc_train_loss 326.11 acc_train_error 9.20% test_error 19.70%\n",
            "174 acc_train_loss 314.77 acc_train_error 7.90% test_error 18.50%\n",
            "175 acc_train_loss 303.86 acc_train_error 8.40% test_error 19.30%\n",
            "176 acc_train_loss 296.99 acc_train_error 8.00% test_error 18.10%\n",
            "177 acc_train_loss 293.06 acc_train_error 8.10% test_error 19.80%\n",
            "178 acc_train_loss 291.21 acc_train_error 8.00% test_error 18.60%\n",
            "179 acc_train_loss 292.04 acc_train_error 8.60% test_error 20.20%\n",
            "180 acc_train_loss 294.65 acc_train_error 8.10% test_error 18.70%\n",
            "181 acc_train_loss 301.16 acc_train_error 8.90% test_error 21.20%\n",
            "182 acc_train_loss 309.24 acc_train_error 8.30% test_error 20.00%\n",
            "183 acc_train_loss 318.34 acc_train_error 9.50% test_error 21.90%\n",
            "184 acc_train_loss 323.10 acc_train_error 8.60% test_error 20.50%\n",
            "185 acc_train_loss 318.36 acc_train_error 9.70% test_error 20.30%\n",
            "186 acc_train_loss 311.68 acc_train_error 7.50% test_error 19.10%\n",
            "187 acc_train_loss 301.40 acc_train_error 9.10% test_error 18.00%\n",
            "188 acc_train_loss 297.30 acc_train_error 6.90% test_error 19.20%\n",
            "189 acc_train_loss 294.66 acc_train_error 8.20% test_error 18.00%\n",
            "190 acc_train_loss 296.65 acc_train_error 7.20% test_error 19.70%\n",
            "191 acc_train_loss 300.50 acc_train_error 8.60% test_error 18.70%\n",
            "192 acc_train_loss 306.77 acc_train_error 7.60% test_error 21.70%\n",
            "193 acc_train_loss 312.66 acc_train_error 9.00% test_error 19.10%\n",
            "194 acc_train_loss 313.50 acc_train_error 8.60% test_error 20.60%\n",
            "195 acc_train_loss 311.71 acc_train_error 8.60% test_error 18.60%\n",
            "196 acc_train_loss 303.17 acc_train_error 7.40% test_error 18.70%\n",
            "197 acc_train_loss 299.14 acc_train_error 7.10% test_error 18.60%\n",
            "198 acc_train_loss 296.53 acc_train_error 7.00% test_error 18.30%\n",
            "199 acc_train_loss 299.17 acc_train_error 7.20% test_error 20.20%\n"
          ]
        }
      ]
    }
  ]
}